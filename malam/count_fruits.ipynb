{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyarw/automatic-segmentation-fruits/blob/main/count_fruits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvhEGBDj4Nbj"
      },
      "source": [
        "# **Count number of fruits from an image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d_s6ywM44sR"
      },
      "source": [
        "In harvesting of fruits, it is a tedious task to manually count and analyse fruits. Image processing techniques can be used to mask out the fruits from the plants. This minimises the manual labour and effort to analyse and recognise ripened fruits on plants.  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![flowchart](flowchart.jpg \"Flowchart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idPB9oKT4UcL"
      },
      "source": [
        "## Input\n",
        "Read the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dPFXtXmdbKDM",
        "outputId": "6d8a7af0-131c-42a3-f607-a89670f0f8f2"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('fruits.jpg')\n",
        "#show the image\n",
        "im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(im_rgb), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShSwzB0U4-Lf"
      },
      "source": [
        "## Grayscale\n",
        "Convert the image to grayscale. The colour of fruits makes them a lighter shade than the background leaves, making it easier to detect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "atN2QJWuPLNG",
        "outputId": "60a34504-8d1c-47de-9d4a-b9a51b62711a"
      },
      "outputs": [],
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray, cmap='gray'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f65XWl4_5CH1"
      },
      "source": [
        "## Gaussian filter\n",
        "Remove noise from image and reduce contrast, otherwise the leaves will be highlighted more if there is more contrast. Use gaussian filter for the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "YHv-MQkBPpMi",
        "outputId": "28bbd991-fb7d-482e-84e6-445dc84edc6d"
      },
      "outputs": [],
      "source": [
        "blur = cv2.GaussianBlur(gray,(25,25),0)\n",
        "plt.imshow(blur, cmap='gray'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# metode 1\n",
        "dengan watershed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "brightness = -140\n",
        "contrast = 90\n",
        "tmp = np.int16(blur)\n",
        "tmp = tmp * (contrast/127+1) - contrast + brightness\n",
        "tmp = np.clip(tmp, 0, 255)\n",
        "adjusted = np.uint8(tmp)\n",
        "plt.imshow(adjusted, cmap='gray'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#threshold\n",
        "ret, thresh = cv2.threshold(adjusted,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "plt.imshow(thresh, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# noise removal\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "plt.imshow(opening, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sure background area\n",
        "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "plt.imshow(sure_bg, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finding sure foreground area\n",
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
        "plt.imshow(dist_transform, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ret, sure_fg = cv2.threshold(dist_transform,0.1*dist_transform.max(),255,0)\n",
        "plt.imshow(sure_fg, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "plt.imshow(unknown, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Marker labelling\n",
        "ret, markers = cv2.connectedComponents(sure_fg)\n",
        "markers = markers+1\n",
        "# Now, mark the region of unknown with zero\n",
        "markers[unknown==255] = 0\n",
        "plt.imshow(markers), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "markers = cv2.watershed(img,markers)\n",
        "img[markers == -1] = [255,0,0]\n",
        "plt.imshow(markers), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_img = img.copy()\n",
        "conts,h=cv2.findContours(sure_fg.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "number_of_objects_in_image= len(conts)\n",
        "print(\"jumlah buah: \"+str(number_of_objects_in_image))\n",
        "for i in range(len(conts)):\n",
        "    x,y,w,h=cv2.boundingRect(conts[i])\n",
        "    cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,255), 2)\n",
        "    cv2.putText(new_img, str(i+1),(x,y+h),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,255))\n",
        "# show the image\n",
        "im_rgb = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(im_rgb), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TrPG7t4l5Tit"
      },
      "source": [
        "# metode 2\n",
        "## K-means clustering\n",
        "Apply k-means clustering to split the image into 6 regions depending on pixel values. This will smoothen the textures in the image and help us choose a common region in the image that belong only to the fruits (region segmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "-cXmza5DNc3V",
        "outputId": "66bf970a-dae0-4629-9e1c-6265413bae31"
      },
      "outputs": [],
      "source": [
        "# convert the image to a 2D array of pixels\n",
        "pixel_values = blur.reshape((-1, 3))\n",
        "# convert to float\n",
        "pixel_values = np.float32(pixel_values)\n",
        "\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "k = 6 # number of clusters k\n",
        "\n",
        "_, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "centers = np.uint8(centers)\n",
        "labels = labels.flatten()\n",
        "segmented_image = centers[labels.flatten()]\n",
        "segmented_image = segmented_image.reshape(blur.shape)\n",
        "\n",
        "# show the image\n",
        "plt.imshow(segmented_image, cmap='gray'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YSi4hzY5z5n"
      },
      "source": [
        "## Threshold\n",
        "Apply binary thresholding to the image and select the brightest pixels. Here the region selected lies above 165 pixels (region segmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "eQIakPT5N1QS",
        "outputId": "67ee2ddd-a0d6-4240-9402-6131dfae260a"
      },
      "outputs": [],
      "source": [
        "_, thresh = cv2.threshold(segmented_image, 165, 255, 0)\n",
        "# show the image\n",
        "plt.imshow(thresh, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxgZnioE58p4"
      },
      "source": [
        "## Canny Edge Detection\n",
        "Perform canny edge detection. This will give us the boundaries, to later help accurately plot and detect the contour lines (edge segmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "JZlc3HHLN_2u",
        "outputId": "bae0f626-146e-4a2d-eca9-cb7c98ffedc9"
      },
      "outputs": [],
      "source": [
        "edges = cv2.Canny(thresh,120,200)\n",
        "# show the image\n",
        "plt.imshow(edges, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp8gMTmT6Dhi"
      },
      "source": [
        "## Closing\n",
        "Perform a closing operation (dilation followed by erosion) on the given image. This will help us join the broken cracks together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "CrxGSigfP4Xo",
        "outputId": "6180f580-c74a-484b-9533-72b9bdf4ecba"
      },
      "outputs": [],
      "source": [
        "kernelClose=np.ones((8,8))\n",
        "closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernelClose)\n",
        "# show the image\n",
        "plt.imshow(closing, cmap='binary_r'), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DFbGbeI6NVU"
      },
      "source": [
        "## Output\n",
        "Find the contours in the segmented image. Plot the detected fruits and count them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "rniR9E4koCM7",
        "outputId": "00f035d8-a891-4443-8be5-ff384a2f86e3"
      },
      "outputs": [],
      "source": [
        "new_img = img.copy()\n",
        "conts,h=cv2.findContours(closing.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "for i in range(len(conts)):\n",
        "    x,y,w,h=cv2.boundingRect(conts[i])\n",
        "    cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,255), 2)\n",
        "    cv2.putText(new_img, str(i+1),(x,y+h),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,255))\n",
        "# show the image\n",
        "im_rgb = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(im_rgb), plt.grid(False)\n",
        "plt.xticks([]), plt.yticks([])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMlqTn1V1EA6ZfCvY2trpJd",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "count-fruits.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pcd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5649037b633350cc4136c4b05a8a2a59030fe7da7c635e857fbddfa76a4c0dcc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
